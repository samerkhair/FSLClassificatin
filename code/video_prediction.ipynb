{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torchvision import transforms, models ,datasets\nfrom torch import nn,optim\nfrom torch.nn import Module\nfrom torch.nn import Conv2d\nfrom torch.nn import Linear\nfrom torch.nn import MaxPool2d\nfrom torch.nn import ReLU\nfrom torch.nn import LogSoftmax\nfrom torch import flatten\nfrom torch.optim import Adam\nfrom torch import nn\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport glob\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2023-07-02T15:41:46.644906Z","iopub.execute_input":"2023-07-02T15:41:46.645198Z","iopub.status.idle":"2023-07-02T15:41:51.895765Z","shell.execute_reply.started":"2023-07-02T15:41:46.645173Z","shell.execute_reply":"2023-07-02T15:41:51.894519Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#Section 2\nimport time\n\nnum_groups = 4\n\nclass SVHN_NN(nn.Module):\n    \"\"\"CNN for the SVHN Datset\"\"\"\n    def __init__(self):\n        \"\"\"CNN Builder.\"\"\"\n        super(SVHN_NN, self).__init__()\n        self.conv_layer = nn.Sequential(\n            # Conv Layer block 1\n            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n            # `paading=1` is the same as `padding='same'` for 3x3 kernels size\n            nn.GroupNorm(num_groups, 32, eps=1e-05, affine=True, device=None, dtype=None),\n            #nn.BatchNorm2d(32),\n            nn.PReLU(),\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n            nn.PReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            # Conv Layer block 2\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n            nn.GroupNorm(num_groups*num_groups, 128, eps=1e-05, affine=True, device=None, dtype=None),\n            #nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n            nn.PReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Dropout2d(p=0.05),\n            # Conv Layer block 3\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n            nn.GroupNorm(8*num_groups, 256, eps=1e-05, affine=True, device=None, dtype=None),\n            #nn.BatchNorm2d(256),\n            nn.PReLU(),\n            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(in_channels=256, out_channels=128, kernel_size=7, padding=1),\n            nn.PReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Dropout2d(p=0.05),\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=15, padding=1),\n            nn.GroupNorm(8*num_groups, 256, eps=1e-05, affine=True, device=None, dtype=None),\n            )\n        \n        self.fc_layer = nn.Sequential(\n            nn.Dropout(p=0.1),\n            nn.Linear(1024, 512),\n            nn.PReLU(),\n            nn.Linear(512, 256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.1),\n            nn.Linear(256,1024),\n            nn.Dropout(p=0.1),\n            nn.PReLU(),\n            nn.Linear(1024,256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.1),\n            nn.Linear(256,128),\n            nn.Dropout(p=0.1),\n            nn.Linear(128,27)\n            )\n        \n\n    def forward(self, x):\n            \"\"\"Perform forward.\"\"\"\n\n            # conv layers\n            x = self.conv_layer(x)\n\n            # flatten\n            x = x.view(x.size(0), -1)\n\n            # fc layer\n            x = self.fc_layer(x)\n            return x\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-02T15:41:57.507076Z","iopub.execute_input":"2023-07-02T15:41:57.507618Z","iopub.status.idle":"2023-07-02T15:41:57.524274Z","shell.execute_reply.started":"2023-07-02T15:41:57.507588Z","shell.execute_reply":"2023-07-02T15:41:57.523329Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ncriterion = nn.CrossEntropyLoss()\nmodel = SVHN_NN()\n# change the path to your path\nmodel.load_state_dict(torch.load('/kaggle/input/final3-classifier/classifier.pth'))\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-02T15:46:50.642063Z","iopub.execute_input":"2023-07-02T15:46:50.642533Z","iopub.status.idle":"2023-07-02T15:46:54.320796Z","shell.execute_reply.started":"2023-07-02T15:46:50.642494Z","shell.execute_reply":"2023-07-02T15:46:54.319875Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"SVHN_NN(\n  (conv_layer): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): GroupNorm(4, 32, eps=1e-05, affine=True)\n    (2): PReLU(num_parameters=1)\n    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): PReLU(num_parameters=1)\n    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): GroupNorm(16, 128, eps=1e-05, affine=True)\n    (8): ReLU(inplace=True)\n    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (10): PReLU(num_parameters=1)\n    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (12): Dropout2d(p=0.05, inplace=False)\n    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (14): GroupNorm(32, 256, eps=1e-05, affine=True)\n    (15): PReLU(num_parameters=1)\n    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (17): ReLU(inplace=True)\n    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (19): Conv2d(256, 128, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n    (20): PReLU(num_parameters=1)\n    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (22): Dropout2d(p=0.05, inplace=False)\n    (23): Conv2d(128, 256, kernel_size=(15, 15), stride=(1, 1), padding=(1, 1))\n    (24): GroupNorm(32, 256, eps=1e-05, affine=True)\n  )\n  (fc_layer): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=1024, out_features=512, bias=True)\n    (2): PReLU(num_parameters=1)\n    (3): Linear(in_features=512, out_features=256, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.1, inplace=False)\n    (6): Linear(in_features=256, out_features=1024, bias=True)\n    (7): Dropout(p=0.1, inplace=False)\n    (8): PReLU(num_parameters=1)\n    (9): Linear(in_features=1024, out_features=256, bias=True)\n    (10): ReLU(inplace=True)\n    (11): Dropout(p=0.1, inplace=False)\n    (12): Linear(in_features=256, out_features=128, bias=True)\n    (13): Dropout(p=0.1, inplace=False)\n    (14): Linear(in_features=128, out_features=27, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"classes = {\n    0: \"A\",\n    1: \"B\",\n    2: \"BLANK\",\n    3: \"C\",\n    4: \"D\",\n    5: \"E\",\n    6: \"F\",\n    7: \"G\",\n    8: \"H\",\n    9: \"I\",\n    10: \"J\",\n    11: \"K\",\n    12: \"L\",\n    13: \"M\",\n    14: \"N\",\n    15: \"O\",\n    16: \"P\",\n    17: \"Q\",\n    18: \"R\",\n    19: \"S\",\n    20: \"T\",\n    21: \"U\",\n    22: \"V\",\n    23: \"W\",\n    24: \"X\",\n    25: \"Y\",\n    26: \"Z\",\n\n}","metadata":{"execution":{"iopub.status.busy":"2023-07-02T15:46:58.158869Z","iopub.execute_input":"2023-07-02T15:46:58.159256Z","iopub.status.idle":"2023-07-02T15:46:58.165990Z","shell.execute_reply.started":"2023-07-02T15:46:58.159226Z","shell.execute_reply":"2023-07-02T15:46:58.164960Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\ndef predict_sign(sign_path):\n    \n    test_img = Image.open(sign_path)\n\n\n\n    # Define transformations\n    t_r = transforms.Resize((256,256))\n    t_t = transforms.ToTensor()\n\n    image = test_img\n\n    # Apply transformations\n    test_img = t_r(test_img)\n    test_img = t_t(test_img)\n    \n\n\n    image_predicted = test_img\n    # Convert tensor to numpy array\n    image_predicted_np = image_predicted.cpu().numpy()\n    # Transpose dimensions to match the expected shape\n    image_predicted_np = np.transpose(image_predicted_np, (1, 2, 0))\n\n\n    # Move the tensor to CUDA if available\n    if torch.cuda.is_available():\n        test_img = test_img.cuda()\n\n    \n    test_img = test_img.unsqueeze(0)  # Add an extra dimension for the batch size\n\n    # Move the tensor to GPU if available\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    test_img = test_img.to(device)\n\n    #classify image using our model\n    res = torch.exp(model(test_img))\n\n    _, predicted_label = torch.max(res, 1)\n    \n    prediction = classes[res.argmax().item()]\n    return prediction,image,image_predicted_np\n","metadata":{"execution":{"iopub.status.busy":"2023-07-02T14:01:58.809440Z","iopub.execute_input":"2023-07-02T14:01:58.809829Z","iopub.status.idle":"2023-07-02T14:01:58.820441Z","shell.execute_reply.started":"2023-07-02T14:01:58.809800Z","shell.execute_reply":"2023-07-02T14:01:58.819353Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**cut video to frames**","metadata":{}},{"cell_type":"code","source":"!pip install opencv-python\n","metadata":{"execution":{"iopub.status.busy":"2023-07-01T11:26:27.933727Z","iopub.execute_input":"2023-07-01T11:26:27.934254Z","iopub.status.idle":"2023-07-01T11:26:41.136189Z","shell.execute_reply.started":"2023-07-01T11:26:27.934214Z","shell.execute_reply":"2023-07-01T11:26:41.134869Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.7.0.72)\nRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.23.5)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"! mkdir video_frames","metadata":{"execution":{"iopub.status.busy":"2023-07-01T15:37:04.082638Z","iopub.execute_input":"2023-07-01T15:37:04.084107Z","iopub.status.idle":"2023-07-01T15:37:05.172162Z","shell.execute_reply.started":"2023-07-01T15:37:04.084057Z","shell.execute_reply":"2023-07-01T15:37:05.170588Z"},"trusted":true},"execution_count":318,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\n\ndef get_majority_label(labels):\n    label_counts = Counter(labels)\n    majority_label = label_counts.most_common(1)[0][0]\n    return majority_label","metadata":{"execution":{"iopub.status.busy":"2023-07-02T14:02:11.129638Z","iopub.execute_input":"2023-07-02T14:02:11.130030Z","iopub.status.idle":"2023-07-02T14:02:11.136107Z","shell.execute_reply.started":"2023-07-02T14:02:11.130001Z","shell.execute_reply":"2023-07-02T14:02:11.134614Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import cv2\nfrom IPython.display import Image, display\nimport numpy as np\nfrom PIL import Image\nimport cv2\nimport torch\nfrom torchvision import transforms\nfrom collections import Counter\n\ndef detect_motion6(video_path):\n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        raise ValueError(\"Error opening video file.\")\n\n    frame_count = 0\n    prev_frame_gray = None\n    black_flag = 0\n    b_im_displayed = 0\n    sign_arr = []\n    predictions_arr = []\n    sign_cnt = 0\n    num_signs = 1\n    word = []\n    while True:\n        ret, curr_frame = cap.read()\n        if not ret:\n            break\n\n        # Convert the current frame to grayscale\n        curr_frame_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n\n        # Perform background subtraction\n        if prev_frame_gray is not None:\n            diff_frame = cv2.absdiff(curr_frame_gray, prev_frame_gray)\n\n            # Apply thresholding to obtain binary image\n            _, threshold = cv2.threshold(diff_frame, 30, 255, cv2.THRESH_BINARY)\n\n            # Perform contour detection\n            contours, _ = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n            motion_detected = False\n\n            # Iterate over detected contours\n            for contour in contours:\n                # Filter out small contours\n                if cv2.contourArea(contour) > 1000:\n                    x, y, w, h = cv2.boundingRect(contour)\n                    cv2.rectangle(curr_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n                    motion_detected = True\n\n            if not motion_detected:\n                # Display the frame with bounding boxes indicating motion\n                #display(Image(data=cv2.imencode('.jpg', curr_frame)[1].tobytes()))\n                \n                # Save the frame to the output directory\n                #output_path = f\"{output_dir}/frame_{frame_count}.jpg\"\n                sign_arr.append(curr_frame)\n                sign_cnt +=1\n                #cv2.imwrite(output_path, curr_frame)\n                black_flag = 1\n                b_im_displayed = 0\n            else : \n                black_flag = 0\n                \n                if sign_cnt > 10:\n                    #directory_name = os.path.join(output_dir, str(num_signs))\n                    #os.mkdir(directory_name)\n                    tmp_frame_num = 0\n                    for saved_frame in sign_arr :\n                        tmp_frame_path = \"/kaggle/working/tmp_frame.jpg\"\n                        tmp_frame_num += 1\n                        cv2.imwrite(tmp_frame_path, saved_frame)\n                        predictions_arr.append(predict_sign(tmp_frame_path)[0])\n                        #print(predict_sign(tmp_frame_path)[0])\n                    sign_prediction = get_majority_label(predictions_arr)\n                    word.append(sign_prediction)\n                    #print(sign_prediction)\n                    num_signs += 1\n                    sign_cnt = 0\n                    sign_arr = []\n                    predictions_arr = []\n\n                \n            if black_flag == 0 :\n                height, width, channels = curr_frame.shape\n                # Create a black image with the same shape\n                black_image = np.zeros((height, width, channels))#, dtype=np.uint8)\n                if b_im_displayed == 0 :\n                    #print(\"**********************************************\")\n                    #display(Image(data=cv2.imencode('.jpg', black_image)[1].tobytes()))\n                    #output_path = f\"{output_dir}/frame_{frame_count}.jpg\"\n                    #cv2.imwrite(output_path, curr_frame)\n                    b_im_displayed = 1\n                black_flag = 1\n                \n                \n\n        prev_frame_gray = curr_frame_gray\n        frame_count += 1\n\n    if sign_cnt > 10:\n        #directory_name = os.path.join(output_dir, str(num_signs))\n        #os.mkdir(directory_name)\n        tmp_frame_num = 0\n        for saved_frame in sign_arr :\n            tmp_frame_path = \"/kaggle/working/tmp_frame.jpg\"\n            tmp_frame_num += 1\n            cv2.imwrite(tmp_frame_path, saved_frame)\n            predictions_arr.append(predict_sign(tmp_frame_path)[0])\n            #print(predict_sign(tmp_frame_path)[0])\n        sign_prediction = get_majority_label(predictions_arr)\n        #print(sign_prediction)\n        word.append(sign_prediction)\n        num_signs += 1\n        sign_cnt = 0\n        sign_arr = []\n        predictions_arr = []\n        \n    cap.release()\n    return word\n    #cv2.destroyAllWindows()","metadata":{"execution":{"iopub.status.busy":"2023-07-02T14:02:13.480750Z","iopub.execute_input":"2023-07-02T14:02:13.481139Z","iopub.status.idle":"2023-07-02T14:02:13.688789Z","shell.execute_reply.started":"2023-07-02T14:02:13.481105Z","shell.execute_reply":"2023-07-02T14:02:13.687843Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def change_label(list_data):\n    old_label = \"BLANK\"\n    new_label = \" \"\n    for i in range(len(list_data)):\n        if list_data[i] == old_label:\n            list_data[i] = new_label\n    return list_data","metadata":{"execution":{"iopub.status.busy":"2023-07-02T14:02:18.195914Z","iopub.execute_input":"2023-07-02T14:02:18.196270Z","iopub.status.idle":"2023-07-02T14:02:18.201648Z","shell.execute_reply.started":"2023-07-02T14:02:18.196242Z","shell.execute_reply":"2023-07-02T14:02:18.200578Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import os\n#export yourn video to a new directory, and replace tha path below with its path\ndirectory = '/kaggle/input/test-videos/videos/videos'\ni = 1\n# Iterate over the files in the directory\nfor filename in os.listdir(directory):\n    if filename.endswith('.mp4'):\n        video_file = os.path.join(directory, filename)\n        name_without_extension = os.path.splitext(filename)[0]\n        word = detect_motion6(video_file)\n        word = change_label(word)\n        word_alligned = ''.join(word)\n        #print(word)\n        print(f\"{i} - real word : \\033[4m{name_without_extension}\\033[0m\")\n        print(f\"{i} - predicted word : \\033[4m{word_alligned}\\033[0m\")\n        print(\"\\n\")\n        i += 1\n","metadata":{"execution":{"iopub.status.busy":"2023-07-02T14:02:56.910534Z","iopub.execute_input":"2023-07-02T14:02:56.910958Z","iopub.status.idle":"2023-07-02T14:04:27.238970Z","shell.execute_reply.started":"2023-07-02T14:02:56.910919Z","shell.execute_reply":"2023-07-02T14:04:27.238002Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"1 - real word : \u001b[4mSAMER\u001b[0m\n1 - predicted word : \u001b[4mSANER\u001b[0m\n\n\n2 - real word : \u001b[4mAPPLE\u001b[0m\n2 - predicted word : \u001b[4mAPPLE\u001b[0m\n\n\n3 - real word : \u001b[4mALAM\u001b[0m\n3 - predicted word : \u001b[4mALAM\u001b[0m\n\n\n4 - real word : \u001b[4mJOBA\u001b[0m\n4 - predicted word : \u001b[4mJOBA\u001b[0m\n\n\n5 - real word : \u001b[4mDEEP\u001b[0m\n5 - predicted word : \u001b[4mDEEP\u001b[0m\n\n\n6 - real word : \u001b[4mNyquist\u001b[0m\n6 - predicted word : \u001b[4mNYQUIST\u001b[0m\n\n\n7 - real word : \u001b[4mWATER\u001b[0m\n7 - predicted word : \u001b[4mWATER\u001b[0m\n\n\n8 - real word : \u001b[4mGym\u001b[0m\n8 - predicted word : \u001b[4mGYM\u001b[0m\n\n\n9 - real word : \u001b[4mTECHNION\u001b[0m\n9 - predicted word : \u001b[4mTECHNOEN\u001b[0m\n\n\n10 - real word : \u001b[4mNoam\u001b[0m\n10 - predicted word : \u001b[4mNOAM\u001b[0m\n\n\n","output_type":"stream"}]}]}